{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import abc\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from numpy import log\n",
    "import sys\n",
    "\n",
    "START_SYMBOL = '<START>'\n",
    "END_SYMBOL = '<END>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare documents\n",
    "\n",
    "Document 1 is a collection of rural news articles and document 2 is a collection of scientific news articles. All articles are from the Australian Broadcasting Commission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_punct = RegexpTokenizer(r\"[\\w'-]+\")\n",
    "\n",
    "FILE1 = 'rural.txt'\n",
    "FILE2 = 'science.txt'\n",
    "\n",
    "doc1_words = rm_punct.tokenize(abc.raw(FILE1).lower())\n",
    "doc2_words = rm_punct.tokenize(abc.raw(FILE2).lower())\n",
    "\n",
    "# doc1_words = word_tokenize(abc.raw(FILE1))\n",
    "# doc2_words = word_tokenize(abc.raw(FILE2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciton to generate unigrams as dictionary where key=word and value=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_unigrams(doc):\n",
    "    unigrams = {}\n",
    "\n",
    "    for word in doc:\n",
    "        if word not in unigrams:\n",
    "            unigrams[word] = 0\n",
    "        unigrams[word] += 1\n",
    "\n",
    "    return unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate bigrams.\n",
    "\n",
    "Returns a dictionary where each key is a word (word1 in a bigram), and each value is another dictionary. The second dictionary has words as keys (word2 in a bigram) and the count of the bigram (word1 word2) as values. So dict[word1][word2] is the count of bigram (word1 word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigrams(doc):\n",
    "    bigrams = {}\n",
    "    prev = START_SYMBOL\n",
    "    # bigrams[prev] = {}\n",
    "    # doc = doc[1:]\n",
    "\n",
    "    for word in doc:\n",
    "        if prev not in bigrams:\n",
    "            bigrams[prev] = {}\n",
    "        if word not in bigrams[prev]:\n",
    "            bigrams[prev][word] = 0\n",
    "        bigrams[prev][word] += 1\n",
    "        prev = word\n",
    "\n",
    "    # Handle end of file\n",
    "    # This might have to be removed if I try to do text generation\n",
    "    if prev not in bigrams:\n",
    "        bigrams[prev] = {}\n",
    "    bigrams[prev][END_SYMBOL] = 1\n",
    "    \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get word counts from bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_from_bigrams(b):\n",
    "    counts = {}\n",
    "    for word1 in b:\n",
    "        counts[word1] = 0\n",
    "        for word2 in b[word1]:\n",
    "            counts[word1] += b[word1][word2]\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate unigram and bigram sets for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = generate_unigrams(doc1_words)\n",
    "u2 = generate_unigrams(doc2_words)\n",
    "\n",
    "b1 = generate_bigrams(doc1_words)\n",
    "b2 = generate_bigrams(doc2_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write unigrams and bigrams to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stdout = sys.stdout\n",
    "\n",
    "with open('Outputs/word_ct_from_b1.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    counts = word_count_from_bigrams(b1)\n",
    "    for word in counts:\n",
    "        print(word, counts[word])\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "with open('Outputs/word_ct_from_u1.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for word in u1:\n",
    "        print(word, u1[word])\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "with open('Outputs/b1_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for word1 in b1:\n",
    "        for word2 in b1[word1]:\n",
    "            print(word1, word2, b1[word1][word2])\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "with open('Outputs/word_ct_from_b2.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    counts = word_count_from_bigrams(b2)\n",
    "    for word in counts:\n",
    "        print(word, counts[word])\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "with open('Outputs/word_ct_from_u2.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for word in u2:\n",
    "        print(word, u2[word])\n",
    "\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "with open('Outputs/b2_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "\n",
    "    for word1 in b2:\n",
    "        for word2 in b2[word1]:\n",
    "            print(word1, word2, b2[word1][word2])\n",
    "\n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to reshape bigrams into a dict where key = bigram (word1 word2) and value=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_bigram(b):\n",
    "    reshaped_b = {}\n",
    "\n",
    "    for word1 in b:\n",
    "        for word2 in b[word1]:\n",
    "            reshaped_b[word1 + \" \" + word2] = b[word1][word2]\n",
    "\n",
    "    return reshaped_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to sort unigrams by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_frequency(u):\n",
    "    return sorted(u.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to sort bigrams by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_frequency(b):\n",
    "    reshaped_b = reshape_bigram(b)\n",
    "\n",
    "    return unigram_frequency(reshaped_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write unigram and bigram frequencies to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_freq = unigram_frequency(u1)\n",
    "u2_freq = unigram_frequency(u2)\n",
    "\n",
    "b1_freq = bigram_frequency(b1)\n",
    "b2_freq = bigram_frequency(b2)\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "with open('Outputs/sorted_u1_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    for u in u1_freq:\n",
    "        print(u[0], u[1])\n",
    "\n",
    "with open('Outputs/sorted_u2_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    for u in u2_freq:\n",
    "        print(u[0], u[1])\n",
    "\n",
    "with open('Outputs/sorted_b1_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    for u in b1_freq:\n",
    "        print(u[0], u[1])\n",
    "\n",
    "with open('Outputs/sorted_b2_counts.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    for u in b2_freq:\n",
    "        print(u[0], u[1])\n",
    "\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some values for computing probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = len(doc1_words)\n",
    "n2 = len(doc2_words)\n",
    "\n",
    "uniques1 = []\n",
    "for word in doc1_words:\n",
    "    uniques1.append(word)\n",
    "\n",
    "uniques2 = []\n",
    "for word in doc2_words:\n",
    "    uniques2.append(word)\n",
    "\n",
    "uniques_combined = set(uniques1 + uniques2)\n",
    "v = len(uniques_combined)\n",
    "\n",
    "b1_reshaped = reshape_bigram(b1)\n",
    "b2_reshaped = reshape_bigram(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to get count of a bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_count(word1, word2, b):\n",
    "    if word1 in b:\n",
    "        if word2 in b[word1]:\n",
    "            return b[word1][word2]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to get count of a unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_count(word, u):\n",
    "    if word in u:\n",
    "        return u[word]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing probability of a bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_probability(word1, word2, b, u, v):\n",
    "    return ((get_bigram_count(word1, word2, b) + 1) / (get_unigram_count(word1, u) + v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the probability of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_probability(sent, b, u, v):\n",
    "    sent = rm_punct.tokenize(sent.lower())\n",
    "    prob = 0\n",
    "    prev = START_SYMBOL\n",
    "\n",
    "    for word in sent:\n",
    "        prob = prob + log(bigram_probability(prev, word, b, u, v))\n",
    "        prev = word\n",
    "    \n",
    "    word = END_SYMBOL\n",
    "    prob = prob * bigram_probability(prev, word, b, u, v)\n",
    "\n",
    "    return prob        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to compare probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(sent, source):\n",
    "    p1 = sent_probability(sent, b1, u1, v)\n",
    "    p2 = sent_probability(sent, b2, u2, v)\n",
    "\n",
    "    print(\"Sentence: \", sent)\n",
    "    print(\"Source: \", source)\n",
    "    print(\"Probability of sentence in document 1: \", p1)\n",
    "    print(\"Probability of sentence in document 2: \", p2)\n",
    "    if(p1 > p2):\n",
    "        print(\"Prediction: doc1\")\n",
    "    else:\n",
    "        print(\"Prediction: doc2\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Output/sentence_probabilities.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s8/rv93pqpx70b4kwk4920_qvg40000gn/T/ipykernel_920/2930894056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moriginal_stdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output/sentence_probabilities.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output/sentence_probabilities.txt'"
     ]
    }
   ],
   "source": [
    "original_stdout = sys.stdout\n",
    "\n",
    "with open(\"Output/sentence_probabilities.txt\", \"w\") as f:\n",
    "\n",
    "    sys.stdout = f\n",
    "\n",
    "    get_probabilities(\"A small number of Western Australian bananas have been sent to the eastern states after a sharp drop in demand.\", \"doc1\")\n",
    "\n",
    "    get_probabilities(\"The long paddock is getting crowded around Narrabri, in north-west New South Wales, where 25,000 head of livestock are searching for feed on the stock routes.\", \"doc1\")\n",
    "\n",
    "    get_probabilities(\"Dr Bernd Irlenbusch of the London School of Economics adds he was surprised with the extent of punishment.\", 'doc2')\n",
    "\n",
    "    get_probabilities(\"Australians are in a prime position to see Mercury moving across the Sun this week, an event they won't be able to see again for another 26 years.\", 'doc2')\n",
    "\n",
    "sys.stdout = original_stdout"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94c5185de908f80e6ab267995bb85cc29c6760e55dbc83b5fed91bd9056ac0dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
